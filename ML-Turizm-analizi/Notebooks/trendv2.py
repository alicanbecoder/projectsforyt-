# -*- coding: utf-8 -*-
"""
Created on Thu Oct 30 19:33:25 2025

@author: Alican
"""

from pytrends.request import TrendReq
import pandas as pd
import numpy as np  # np.nan kullanimi iÃ§in eklendi
import time
import random

# ğŸŒ Odak Ã¼lkeler (Ayni)
countries = {
    "DE": "Germany",
    "US": "United States",
    "NL": "Netherlands",
    "GB": "United Kingdom",
    "IR": "Iran",
    "KZ": "Kazakhstan",
    "PL": "Poland",
    "RO": "Romania",
    "RU": "Russia",
    "SA": "Saudi Arabia"
}

# ğŸ”‘ Anahtar kelime seti (Ayni)
keywords = [
    # Genel TÃ¼rkiye turizmi
    "Turkey travel", "Turkey holiday", "visit Turkey", "Turkey vacation",
    "Turkey tourism", "Turkey trip", "Turkey resorts", "Turkey beaches",
    "flights to Turkey", "Turkey all inclusive", "Turkey family holiday",

    # Åehir & bÃ¶lge bazlÄ±
    "Antalya holiday", "Antalya hotel", "Antalya resort", "Antalya beach",
    "Istanbul trip", "Istanbul travel", "Istanbul hotel", "Istanbul city break",
    "Cappadocia hot air balloon", "Cappadocia travel", "Cappadocia cave hotel",
    "Bodrum beach", "Bodrum hotel", "Fethiye holiday", "Marmaris hotel",
    "Izmir travel", "Alanya hotel", "Kusadasi resort",

    # Fiyat & sezon & rezervasyon
    "Turkey cheap hotels", "Turkey all inclusive resorts", "Turkey summer vacation",
    "best time to visit Turkey", "Turkey weather", "Turkey hotel deals",
    "Turkey flights", "Turkey visa", "Turkey e-visa",

    # KÃ¼ltÃ¼r & gastronomi
    "Turkish food", "Turkish culture", "Turkish coffee", "Istanbul shopping",
    "Grand Bazaar Istanbul", "Pamukkale", "Ephesus Turkey", "Turkish bath"
]

# ğŸ“ YÃ–NTEM: Ã‡apa (Anchor) Kelimeyi Belirle
# Bu kelime, tÃ¼m karsilastirmalar iÃ§in temel alinacak.
anchor_keyword = "Turkey travel"

# DiÄŸer kelimeleri Ã§apadan ayÄ±r (4'lÃ¼ gruplar halinde sorgulanacaklar)
other_keywords = [k for k in keywords if k != anchor_keyword]

# ğŸ§  TrendReq baÅŸlat
pytrends = TrendReq(hl='en-US', tz=360)
all_data = []

# ğŸ“† Tarih aralÄ±ÄŸÄ±
timeframe = '2022-01-01 2024-12-31'

# ğŸ”„ Her Ã¼lke iÃ§in veri Ã§ek
for code, name in countries.items():
    print(f"\nğŸŒ {name} ({code}) iÃ§in veriler Ã§ekiliyor...\n")
    
    # 1. ADIM: Baz Puan (Baseline) Verisini Ã‡ek
    # Sadece Ã§apa kelimenin trendini alarak ana Ã¶lÃ§eÄŸimizi oluÅŸturuyoruz.
    print(f"  ğŸ”¹ Baz puan alÄ±nÄ±yor: [{anchor_keyword}]")
    df_baseline = None
    retries = 0
    success = False
    
    while not success and retries < 5:
        try:
            pytrends.build_payload([anchor_keyword], cat=67, timeframe=timeframe, geo=code)
            df_baseline = pytrends.interest_over_time()
            df_baseline = df_baseline.drop(columns=['isPartial'], errors='ignore').reset_index()
            
            # SÄ±fÄ±ra bÃ¶lme hatasÄ±nÄ± engellemek iÃ§in 0'larÄ± np.nan ile deÄŸiÅŸtir
            df_baseline[f'{anchor_keyword}_safe'] = df_baseline[anchor_keyword].replace(0, np.nan)
            df_baseline['country'] = name
            
            # Bu, Ã¼lkenin ana veri Ã§erÃ§evesi olacak
            country_data = df_baseline.copy()
            success = True
            time.sleep(random.randint(5, 10))
            
        except Exception as e:
            retries += 1
            print(f"  âš ï¸ BAZ PUAN hatasÄ± ({retries}. deneme): {e}")
            time.sleep(30)

    if not success:
        print(f"  âŒ {name} iÃ§in baz puan alÄ±namadÄ±. Bu Ã¼lke atlanÄ±yor.")
        continue

    # 2. ADIM: DiÄŸer Kelimeleri 4'lÃ¼ Gruplar Halinde Ã‡ek ve Ã–lÃ§ekle
    for i in range(0, len(other_keywords), 4):
        group_of_4 = other_keywords[i:i+4]
        query_group = [anchor_keyword] + group_of_4  # Ã‡apa kelimeyi gruba ekle
        
        print(f"  ğŸ”¹ {query_group} sorgulanÄ±yor...")
        
        success = False
        retries = 0

        while not success and retries < 5:
            try:
                pytrends.build_payload(query_group, cat=67, timeframe=timeframe, geo=code)
                df_temp = pytrends.interest_over_time()
                df_temp = df_temp.drop(columns=['isPartial'], errors='ignore').reset_index()

                # Bu gruptaki Ã§apa kelimenin 0'larÄ±nÄ± da nan yap
                df_temp[anchor_keyword] = df_temp[anchor_keyword].replace(0, np.nan)

                # 3. ADIM: NORMALÄ°ZASYON VE Ã–LÃ‡EKLEME
                # Bu bÃ¶lÃ¼m, veriyi anlamlÄ± hale getiren en kritik yerdir.
                
                # df_temp'i (geÃ§ici grup) df_baseline (baz puan) ile birleÅŸtir
                df_merged = pd.merge(
                    df_temp,
                    df_baseline[['date', anchor_keyword, f'{anchor_keyword}_safe']],
                    on='date',
                    suffixes=('_group', '_baseline')
                )
                
                # Ã–lÃ§eklenmiÅŸ verileri tutmak iÃ§in yeni bir dataframe
                df_scaled_batch = df_merged[['date']].copy()

                for kw in group_of_4:
                    if kw in df_merged.columns:
                        # 1. GÃ¶receli Oran: Kelimenin, grup iÃ§indeki Ã§apaya oranÄ±
                        relative_ratio = df_merged[kw] / df_merged[f'{anchor_keyword}_group']
                        
                        # 2. Ã–lÃ§eklenmiÅŸ Puan: GÃ¶receli oranÄ±n, ana baz puan ile Ã§arpÄ±mÄ±
                        # (Burada _baseline olanÄ± kullanÄ±yoruz)
                        scaled_score = relative_ratio * df_merged[anchor_keyword + '_baseline']
                        
                        df_scaled_batch[kw] = scaled_score

                # Bu grubun Ã¶lÃ§eklenmiÅŸ verilerini ana Ã¼lke verisiyle birleÅŸtir
                country_data = pd.merge(country_data, df_scaled_batch, on='date', how='outer')
                
                success = True
                time.sleep(random.randint(5, 10)) # API rate limit korumasÄ±
            except Exception as e:
                retries += 1
                print(f"  âš ï¸ GRUP SORGUSU hatasÄ± ({retries}. deneme): {e}")
                time.sleep(30) # hata sonrasÄ± bekleme

    if not country_data.empty:
        all_data.append(country_data)

# ğŸ§© TÃ¼m Ã¼lkeleri birleÅŸtir
print("\nğŸ”„ TÃ¼m veriler birleÅŸtiriliyor...")
final_df = pd.concat(all_data, ignore_index=True)

# ArtÄ±k tÃ¼m kelimeler (Ã§apa dahil) aynÄ± Ã¶lÃ§ekte.
# Ã‡apa kelimenin adÄ±nÄ± netleÅŸtirelim:
final_df = final_df.rename(columns={anchor_keyword: f"{anchor_keyword}_(Scaled)"})

# GÃ¼venli (safe) sÃ¼tunu temizleyelim
final_df = final_df.drop(columns=[f'{anchor_keyword}_safe'], errors='ignore')

final_df = final_df.sort_values(by=['country', 'date']).reset_index(drop=True)

# 4. ADIM: AnlamlÄ± Ortalama Hesapla
# ArtÄ±k tÃ¼m sÃ¼tunlar aynÄ± Ã¶lÃ§ekte olduÄŸu iÃ§in ortalama almak GEÃ‡ERLÄ°DÄ°R.
keyword_cols = [col for col in final_df.columns if col not in ['date', 'country']]
final_df['Average_Interest_SCALED'] = final_df[keyword_cols].mean(axis=1)

# ğŸ’¾ Excel Ã§Ä±ktÄ±sÄ±
output_path = "google_trends_SCALED_2022_2024.xlsx" # Dosya adÄ±nÄ± deÄŸiÅŸtirdim
final_df.to_excel(output_path, index=False)
print("\nâœ… TÃ¼m veriler baÅŸarÄ±yla Ã§ekildi, Ã¶lÃ§eklendi ve kaydedildi!")
print(f"ğŸ“ Kaydedilen dosya: {output_path}") 